{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSentence(s):\n",
    "    sentences = sent_tokenize(s)\n",
    "    return len(sentences)  \n",
    "def removeTitleNumber(line):\n",
    "    foundEnglish = False\n",
    "    newline = ''\n",
    "    words = line.split()\n",
    "    for w in words:\n",
    "        if re.search(r'[A-Za-z]', w[0]):\n",
    "            foundEnglish = True\n",
    "\n",
    "        if foundEnglish == False:\n",
    "            continue\n",
    "        else:\n",
    "            newline = newline + ' ' + w\n",
    "    newline = newline.strip()\n",
    "    return newline\n",
    "\n",
    "def removeTitleNumber2(line):\n",
    "    foundEnglish = False\n",
    "    output = ''\n",
    "    words = line.split()\n",
    "    for w in words:\n",
    "        if foundEnglish:\n",
    "            output += ' ' + w\n",
    "        else:\n",
    "            if re.search(r'[A-Za-z]', w[0]):\n",
    "                foundEnglish = True\n",
    "                output += ' ' + w\n",
    "            if isSpecialChar(w[0]) == True:\n",
    "                output += ' ' + w\n",
    "            else:\n",
    "                continue\n",
    "    output = output.strip()\n",
    "    return output\n",
    "\n",
    "########\n",
    "def checkSentenceEnd(s):\n",
    "    # check sentence is finished or not\n",
    "    if s[-1] in ['.',',',';',':']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def checkLowercase(s):\n",
    "    if re.search(r'[a-z]', s) is None:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "def checkUppercase(s):\n",
    "    if re.search(r'[A-Z]',s) is None:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "# For PDF\n",
    "def isTitle(words):\n",
    "    for word in words:\n",
    "        if word in ['to','for','toward','by','on','a','an']:\n",
    "            continue\n",
    "        if re.search(r'[A-Z]',word[0]) is None:\n",
    "            return False\n",
    "    return True\n",
    "def checkPdfFormatError(s):\n",
    "    words = word_tokenize(s)\n",
    "    if len(words) <= 5:\n",
    "        return False,'LengthError'\n",
    "    elif s.count('..') > 0:\n",
    "        return False,'DuplicatePeriodError'\n",
    "    else:\n",
    "        return True,'Pass'\n",
    "def countSentence(s):\n",
    "    # break paragraph into sentences\n",
    "    sentences = sent_tokenize(s)\n",
    "    # if contains two or more sentences, the paragraph is valid\n",
    "    return len(sentences)\n",
    "\n",
    "def isSpecialChar(char):\n",
    "    bulletSymbol = [61623,8226]\n",
    "    if ord(char) in bulletSymbol :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "# import hashlib\n",
    "# import requests\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "# from elasticsearch import Elasticsearch\n",
    "# from elasticsearch.helpers import bulk \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import logging\n",
    "from docx import Document\n",
    "import collections\n",
    "import sys\n",
    "\n",
    "# initialize for reading document\n",
    "resourceManager = PDFResourceManager()\n",
    "retStr = io.StringIO()\n",
    "laParams = LAParams()\n",
    "converter = TextConverter(resourceManager, retStr, codec='utf-8', laparams=laParams)\n",
    "interpreter = PDFPageInterpreter(resourceManager, converter)\n",
    "count = 0\n",
    "\n",
    "# use for store all paragraphs\n",
    "allParas = []\n",
    "# use for store valid paragraphs\n",
    "validPara = []\n",
    "# buffer status variable\n",
    "PrevSentIsFinished = True\n",
    "# temp variable\n",
    "temp = ''\n",
    "# add to temp count\n",
    "tempCount = 0\n",
    "# add to temp max retries\n",
    "countThreshold = 3\n",
    "# allow sentence count as a paragraph\n",
    "sentenceThreshold = 1\n",
    "# valid sentences list\n",
    "validSentence = []\n",
    "\n",
    "filePath = 'mobile-policy.pdf'\n",
    "\n",
    "# Read all para and store to allParas list\n",
    "with open(filePath, \"rb\") as file:\n",
    "    # read pages\n",
    "    for pageNumber, page in enumerate(PDFPage.get_pages(file)):\n",
    "            if pageNumber > 2:\n",
    "                break\n",
    "            interpreter.process_page(page)\n",
    "            content = retStr.getvalue()\n",
    "\n",
    "            # read para\n",
    "            paras = content.split('\\n\\n') \n",
    "            for para in paras:\n",
    "                # store to allParas list\n",
    "                allParas.append(para)\n",
    "\n",
    "            retStr.truncate(0)\n",
    "            retStr.seek(0)\n",
    "\n",
    "    # Find out duplicated sentences\n",
    "    duplicatedParas = []\n",
    "    for item, count in collections.Counter(allParas).items():\n",
    "        if count > 1: \n",
    "            duplicatedParas.append(item)\n",
    "\n",
    "# Read again, and avoid duplicate sentences, then store valid sentences to validParas list\n",
    "with open(filePath, \"rb\") as file:\n",
    "    # read pages\n",
    "    for pageNumber, page in enumerate(PDFPage.get_pages(file)):\n",
    "            #print(\"========== %d ==========\"  %pageNumber)\n",
    "            if pageNumber <= 1:\n",
    "                continue\n",
    "            interpreter.process_page(page)\n",
    "            content = retStr.getvalue()\n",
    "\n",
    "            # read para\n",
    "            paras = content.split('\\n\\n') #sent_tokenize(content)\n",
    "            for para in paras:\n",
    "                # remove duplicated lines\n",
    "                if para in duplicatedParas:\n",
    "                    continue\n",
    "\n",
    "                # remove spaces from start and end\n",
    "                para = para.strip()\n",
    "                # remove inner spaces\n",
    "                para = ' '.join(para.split())\n",
    "                # remove special chars\n",
    "                para = removeTitleNumber(para)\n",
    "                # append to validPara list\n",
    "                validPara.append([para,pageNumber+1])\n",
    "            retStr.truncate(0)\n",
    "            retStr.seek(0)\n",
    "\n",
    "#Start processing validPara list\n",
    "for paraList in validPara:\n",
    "    para = paraList[0]\n",
    "    pageNumber = paraList[1]\n",
    "    if para == '':\n",
    "        continue\n",
    "    if countSentence(para) >= sentenceThreshold:\n",
    "        # split sentences from paragraph\n",
    "        sentenceList = sent_tokenize(para)\n",
    "        for sentence in sentenceList:\n",
    "            # buffer status not finished\n",
    "            if PrevSentIsFinished == False:\n",
    "                # if current sentence has uppercase at the first letter, give up temp\n",
    "                if checkUppercase(sentence[0]):\n",
    "                    # set buffer status to finished\n",
    "                    PrevSentIsFinished = True\n",
    "                    # clear buffer\n",
    "                    temp = ''\n",
    "                    # initiate count\n",
    "                    tempCount = 0\n",
    "                # setup max retries to prevent keep adding sentences to buffer with no ending\n",
    "                elif tempCount > countThreshold:\n",
    "                    # set buffer status to finished\n",
    "                    PrevSentIsFinished = True\n",
    "                    # clear buffer\n",
    "                    temp = ''\n",
    "                    # initiate count\n",
    "                    tempCount = 0\n",
    "                else:\n",
    "                    # add current sentence to buffer\n",
    "                    temp = temp + sentence\n",
    "                    # pull buffer to sentence\n",
    "                    sentence = temp\n",
    "\n",
    "            \n",
    "            # Check is title or not\n",
    "            words = word_tokenize(sentence)\n",
    "            if isTitle(words):\n",
    "                validSentence.append( [\"TITLE\",pageNumber] )\n",
    "            \n",
    "            # \n",
    "            if isSpecialChar(sentence[0]):\n",
    "                bulletSymbol = sentence[0]\n",
    "                bulletSentenceList = sentence.split(bulletSymbol)\n",
    "                for bulletSentence in bulletSentenceList:\n",
    "                    if bulletSentence == '':\n",
    "                        continue\n",
    "                    validSentence.append([bulletSymbol + bulletSentence,pageNumber])\n",
    "            # Check sentence prefix capitalization\n",
    "            if checkUppercase(sentence[0]):\n",
    "                # Check sentence contain lowercase letters\n",
    "                if checkLowercase(sentence):\n",
    "                    # Check sentence end\n",
    "                    isFinished = checkSentenceEnd(sentence)\n",
    "                    if isFinished:\n",
    "                        # Check sentence format\n",
    "                        isValid, errorMsg = checkPdfFormatError(sentence)\n",
    "                        if isValid:\n",
    "                            # add valid sentence to validSentence list \n",
    "                            validSentence.append([sentence,pageNumber])\n",
    "                        else:\n",
    "                            #logger.info(\"(\" + errorMsg +'): ' + sentence)\n",
    "                            continue\n",
    "\n",
    "                        # set buffer status to finished\n",
    "                        PrevSentIsFinished = True\n",
    "                        # clear temp\n",
    "                        temp = ''\n",
    "                        # initiate count\n",
    "                        tempCount = 0\n",
    "                    # if sentence not finished, add sentence to buffer, change buffer status to unfinished\n",
    "                    else: \n",
    "                        # push buffer\n",
    "                        temp = temp + sentence + ' '\n",
    "                        # add count\n",
    "                        tempCount += 1\n",
    "                        # set buffer status to unfinished\n",
    "                        PrevSentIsFinished = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "All mobile devices attempting to connect to the District network through an unmanaged network (i.e.\n",
      "---\n",
      "Devices that have not been previously approved by IT, are not in compliance with IT’s security policies, or represent any threat to the District network or data will not be allowed to connect.\n",
      "---\n",
      "Laptop computers or personal PCs may only access the District network using a Virtual Private Network (VPN) connection.\n",
      "---\n",
      "Employees using mobile devices and related software for network and data access will, without exception, use secure data management procedures.\n",
      "---\n",
      "All mobile devices must be protected by a strong password.\n",
      "---\n",
      "See the WCCCD’s password policy for additional details.\n",
      "---\n",
      "Employees agree to never disclose their passwords to anyone.\n",
      "---\n",
      "All users of mobile devices must employ reasonable physical security measures.\n",
      "---\n",
      "End users are expected to secure all such devices used for this activity whether or not they are actually in use and/or being carried.\n",
      "---\n",
      "This includes, but is not limited to, passwords, encryption, and physical control of such devices whenever they contain WCCCD data.\n",
      "---\n",
      "Any non-District computers used to synchronize with these devices will have installed anti-virus and anti-malware software deemed necessary by WCCCD’s IT department.\n",
      "---\n",
      "Anti-virus signature files on any additional client machines – such as a home PC – on which this media will be accessed, must be up to date.\n",
      "---\n",
      "IT will manage security policies, network, application, and data access centrally using whatever technology solutions it deems suitable.\n",
      "---\n",
      "Any attempt to contravene or bypass said security implementation will be deemed an intrusion attempt and will be dealt with in accordance with WCCCD’s overarching security policy.\n",
      "---\n",
      "Employees, contractors, Full time faculty, part time faculty and temporary staff will follow all WCCCD-sanctioned data removal procedures to permanently erase WCCCD- specific data from such devices once their use is no longer required.\n",
      "---\n",
      "In the event of a lost or stolen mobile device it is incumbent on the user to report this to IT immediately.\n",
      "---\n",
      "The device will be remotely wiped of all data and locked to prevent access by anyone other than IT.\n",
      "---\n",
      "If the device is recovered, it can be submitted to IT for re- provisioning.\n",
      "---\n",
      "Employees, contractors, Full time faculty, part time faculty and temporary staff will make no modifications of any kind to WCCCD-owned and installed hardware or software without the approval of the WCCCD Division of Information technology.\n",
      "---\n",
      "This includes, but is not limited to, any reconfiguration of the mobile device.\n",
      "---\n",
      "Division of Information Technology reserves the right, through policy enforcement and any other means it deems necessary, to limit the ability of end users to transfer data to and from specific resources on the WCCCD network.\n",
      "---\n",
      "Division of Information Technology can and will establish audit trails and these will be accessed and used without notice.\n",
      "---\n",
      "Such trails will be able to track the attachment of an external device to a PC, and the resulting reports may be used for investigation of possible breaches and/or misuse.\n",
      "---\n",
      "The end user agrees to and accepts that his or her access and/or connection to WCCCD’s networks may be monitored to record dates, times, duration of access, etc., in order to identify unusual usage patterns or other suspicious activity.\n",
      "---\n",
      "This is done in order to identify accounts/computers that may have been compromised by external parties.\n",
      "---\n",
      "In all cases, data protection remains WCCCD’s highest priority.\n",
      "---\n",
      "Policy Non-Compliance Failure to comply with the Mobile Device Acceptable Use Policy may, at the full discretion of the College, result in the suspension of any or all technology use and connectivity privileges, disciplinary action, and possibly termination of employment.\n"
     ]
    }
   ],
   "source": [
    "# count sentence in validSentence list\n",
    "sent_count = 0\n",
    "for sentenceList in validSentence:\n",
    "    sentence = sentenceList[0]\n",
    "    pageNumber = sentenceList[1]\n",
    "    \n",
    "    # if sentence is title, pass\n",
    "    if sentence == 'TITLE':\n",
    "        sent_count += 1\n",
    "        continue\n",
    "    # First sentence in the list\n",
    "    if sent_count == 0:\n",
    "        prev_sent = None\n",
    "        next_sent = validSentence[sent_count+1][0]\n",
    "    # Last sentence in the list\n",
    "    elif sent_count == len(validSentence)-1:\n",
    "        prev_sent = validSentence[sent_count-1][0]\n",
    "        next_sent = None\n",
    "    # Other sentences in the list\n",
    "    else:\n",
    "        prev_sent = validSentence[sent_count-1][0]\n",
    "        next_sent = validSentence[sent_count+1][0]\n",
    "    # if pre and next sentence is title, modify it to None\n",
    "    if prev_sent == 'TITLE':\n",
    "        prev_sent = None\n",
    "    if next_sent == 'TITLE':\n",
    "        next_sent = None\n",
    "    # print logger\n",
    "    print('---')\n",
    "    #print(\"(Prev) \",prev_sent)\n",
    "    #print(\"(Curr) \",sentence)\n",
    "    #print(\"(Next) \",next_sent)\n",
    "    print(sentence)\n",
    "    # add index count\n",
    "    sent_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
